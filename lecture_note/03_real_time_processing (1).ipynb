{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-Time Data Processing with Pandas\n",
    "In this notebook, we will explore how to handle and process real-time data using `pandas`.\n",
    "We will demonstrate how to work with large datasets in chunks and how to aggregate real-time data streams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Loading Data in Chunks\n",
    "Real-time data can arrive in large quantities, so we need to process it in chunks to optimize performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Timestamp  Visitor Count\n",
      "0  2023-01-01 00:00:00              0\n",
      "1  2023-01-01 01:00:00              1\n",
      "2  2023-01-01 02:00:00              2\n",
      "3  2023-01-01 03:00:00              3\n",
      "4  2023-01-01 04:00:00              4\n",
      "                Timestamp  Visitor Count\n",
      "1000  2023-02-11 16:00:00           1000\n",
      "1001  2023-02-11 17:00:00           1001\n",
      "1002  2023-02-11 18:00:00           1002\n",
      "1003  2023-02-11 19:00:00           1003\n",
      "1004  2023-02-11 20:00:00           1004\n",
      "                Timestamp  Visitor Count\n",
      "2000  2023-03-25 08:00:00           2000\n",
      "2001  2023-03-25 09:00:00           2001\n",
      "2002  2023-03-25 10:00:00           2002\n",
      "2003  2023-03-25 11:00:00           2003\n",
      "2004  2023-03-25 12:00:00           2004\n",
      "                Timestamp  Visitor Count\n",
      "3000  2023-05-06 00:00:00           3000\n",
      "3001  2023-05-06 01:00:00           3001\n",
      "3002  2023-05-06 02:00:00           3002\n",
      "3003  2023-05-06 03:00:00           3003\n",
      "3004  2023-05-06 04:00:00           3004\n",
      "                Timestamp  Visitor Count\n",
      "4000  2023-06-16 16:00:00           4000\n",
      "4001  2023-06-16 17:00:00           4001\n",
      "4002  2023-06-16 18:00:00           4002\n",
      "4003  2023-06-16 19:00:00           4003\n",
      "4004  2023-06-16 20:00:00           4004\n",
      "                Timestamp  Visitor Count\n",
      "5000  2023-07-28 08:00:00           5000\n",
      "5001  2023-07-28 09:00:00           5001\n",
      "5002  2023-07-28 10:00:00           5002\n",
      "5003  2023-07-28 11:00:00           5003\n",
      "5004  2023-07-28 12:00:00           5004\n",
      "                Timestamp  Visitor Count\n",
      "6000  2023-09-08 00:00:00           6000\n",
      "6001  2023-09-08 01:00:00           6001\n",
      "6002  2023-09-08 02:00:00           6002\n",
      "6003  2023-09-08 03:00:00           6003\n",
      "6004  2023-09-08 04:00:00           6004\n",
      "                Timestamp  Visitor Count\n",
      "7000  2023-10-19 16:00:00           7000\n",
      "7001  2023-10-19 17:00:00           7001\n",
      "7002  2023-10-19 18:00:00           7002\n",
      "7003  2023-10-19 19:00:00           7003\n",
      "7004  2023-10-19 20:00:00           7004\n",
      "                Timestamp  Visitor Count\n",
      "8000  2023-11-30 08:00:00           8000\n",
      "8001  2023-11-30 09:00:00           8001\n",
      "8002  2023-11-30 10:00:00           8002\n",
      "8003  2023-11-30 11:00:00           8003\n",
      "8004  2023-11-30 12:00:00           8004\n",
      "                Timestamp  Visitor Count\n",
      "9000  2024-01-11 00:00:00           9000\n",
      "9001  2024-01-11 01:00:00           9001\n",
      "9002  2024-01-11 02:00:00           9002\n",
      "9003  2024-01-11 03:00:00           9003\n",
      "9004  2024-01-11 04:00:00           9004\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Simulating a large dataset\n",
    "data = pd.DataFrame({\n",
    "    'Timestamp': pd.date_range(start='2023-01-01', periods=10000, freq='H'),\n",
    "    'Visitor Count': pd.Series(range(10000))\n",
    "})\n",
    "\n",
    "# Saving this as a CSV to simulate a large file\n",
    "data.to_csv('large_dataset.csv', index=False)\n",
    "\n",
    "# Loading the data in chunks\n",
    "chunk_size = 1000  # Defining chunk size\n",
    "chunks = pd.read_csv('large_dataset.csv', chunksize=chunk_size)\n",
    "\n",
    "# Processing each chunk\n",
    "for chunk in chunks:\n",
    "    print(chunk.head())  # Display the first 5 rows of each chunk\n",
    "    # Perform operations on each chunk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Real-Time Data Aggregation\n",
    "Aggregating real-time data streams can help provide insights on the fly.\n",
    "We will demonstrate how to aggregate visitor counts in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Visitors So Far: 499500\n",
      "Total Visitors So Far: 1999000\n",
      "Total Visitors So Far: 4498500\n",
      "Total Visitors So Far: 7998000\n",
      "Total Visitors So Far: 12497500\n",
      "Total Visitors So Far: 17997000\n",
      "Total Visitors So Far: 24496500\n",
      "Total Visitors So Far: 31996000\n",
      "Total Visitors So Far: 40495500\n",
      "Total Visitors So Far: 49995000\n"
     ]
    }
   ],
   "source": [
    "# Simulating data streaming by processing the dataset in chunks and aggregating the visitor count\n",
    "total_visitors = 0\n",
    "\n",
    "for chunk in pd.read_csv('large_dataset.csv', chunksize=chunk_size):\n",
    "    # Aggregating visitor count in real-time\n",
    "    total_visitors += chunk['Visitor Count'].sum()\n",
    "    print(f'Total Visitors So Far: {total_visitors}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Integrating Real-Time Data with an API\n",
    "Real-time data often comes from APIs. In this section, we will simulate pulling real-time data from an API and processing it using `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Visitor Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-09-18 12:00:00</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Timestamp  Visitor Count\n",
       "0 2023-09-18 12:00:00            150"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Simulating an API call for real-time data\n",
    "api_url = 'https://api.example.com/real_time_data'\n",
    "# Simulated API response (mocking an API call)\n",
    "api_response = {\n",
    "    'Timestamp': '2023-09-18 12:00:00',\n",
    "    'Visitor Count': 150\n",
    "}\n",
    "\n",
    "# Convert API response to DataFrame and process\n",
    "real_time_data = pd.DataFrame([api_response])\n",
    "real_time_data['Timestamp'] = pd.to_datetime(real_time_data['Timestamp'])\n",
    "real_time_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this notebook, we have demonstrated:\n",
    "- How to load and process large datasets in chunks.\n",
    "- How to perform real-time data aggregation.\n",
    "- How to simulate real-time data from an API and integrate it into a `pandas` DataFrame.\n",
    "\n",
    "Next, we will explore Change Data Capture (CDC) in the following notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
