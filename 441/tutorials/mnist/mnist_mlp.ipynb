{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35ac9beb-326e-4f40-aa98-1b15dafd16f7",
   "metadata": {},
   "source": [
    "### **MNIST Classification Tutorial with PyTorch**\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Overview**\n",
    "\n",
    "In this tutorial, we will build a simple neural network to classify handwritten digits from the MNIST dataset. We'll cover the following topics:\n",
    "\n",
    "1. **Data Loading**: Loading and preprocessing the MNIST dataset.\n",
    "2. **Model Definition**: Defining a neural network for classification.\n",
    "3. **Training**: Using an optimizer and a loss function to train the model.\n",
    "4. **Evaluation**: Assessing the model's performance on the test set.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Data Loading**\n",
    "\n",
    "The MNIST dataset consists of 28x28 grayscale images of handwritten digits (0-9) and their corresponding labels.\n",
    "\n",
    "### **Loading the Dataset**\n",
    "\n",
    "PyTorch provides utilities to easily load and preprocess the MNIST dataset. We'll use the `torchvision` library.\n",
    "\n",
    "### **Code:**\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=False)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Model Definition**\n",
    "\n",
    "We'll define a simple neural network with two fully connected layers to classify the MNIST images.\n",
    "\n",
    "### **Model Architecture:**\n",
    "\n",
    "1. **Input Layer**: The input is a flattened 28x28 image (784 input features).\n",
    "2. **Hidden Layer**: A fully connected layer with 128 neurons and ReLU activation.\n",
    "3. **Output Layer**: A fully connected layer with 10 neurons (one for each digit) and a softmax activation.\n",
    "\n",
    "### **Code:**\n",
    "\n",
    "```python\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MNISTClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)  # First fully connected layer\n",
    "        self.fc2 = nn.Linear(128, 10)       # Output layer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)  # Flatten the input image\n",
    "        x = F.relu(self.fc1(x))  # Apply ReLU activation\n",
    "        x = self.fc2(x)          # Compute output logits\n",
    "        return F.log_softmax(x, dim=1)  # Apply log-softmax for classification\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Training the Model**\n",
    "\n",
    "### **Loss Function:**\n",
    "\n",
    "For multi-class classification, we use the negative log-likelihood loss, which is provided by `torch.nn.NLLLoss`.\n",
    "\n",
    "### **Optimizer:**\n",
    "\n",
    "We will use the Adam optimizer for training.\n",
    "\n",
    "### **Training Loop:**\n",
    "\n",
    "We'll train the model for a specified number of epochs, updating the weights after each mini-batch.\n",
    "\n",
    "### **Code:**\n",
    "\n",
    "```python\n",
    "import torch.optim as optim\n",
    "\n",
    "# Instantiate the model, define the loss function and the optimizer\n",
    "model = MNISTClassifier()\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in trainloader:\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(trainloader):.4f}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Evaluation**\n",
    "\n",
    "After training the model, we evaluate its performance on the test dataset to see how well it generalizes.\n",
    "\n",
    "### **Code:**\n",
    "\n",
    "```python\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in testloader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy: {100 * correct / total:.2f}%\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **Conclusion**\n",
    "\n",
    "By following these steps, we've built and trained a simple neural network for MNIST digit classification using PyTorch. The model was trained on the MNIST dataset, and its performance was evaluated on the test set.\n",
    "\n",
    "If you'd like to expand this tutorial further or add advanced techniques such as regularization, additional layers, or hyperparameter tuning, please let me know!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb1ae71-305c-47db-8eab-3bf32d948819",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
