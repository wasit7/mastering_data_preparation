{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f818ecd",
   "metadata": {},
   "source": [
    "\n",
    "# Week 6: Image Generation\n",
    "## Objective:\n",
    "In this notebook, we will explore the concepts of image generation, focusing on Image2Image and Text2Image models. We will implement an image generation model using GANs (Generative Adversarial Networks) and explore how models like Pix2Pix are used for image translation tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eae7b7b",
   "metadata": {},
   "source": [
    "\n",
    "## 6.1 Theory: What is Image Generation?\n",
    "Image generation refers to the process of creating new images using machine learning models. Two popular types of image generation are:\n",
    "- **Image2Image Translation**: Converts an input image from one domain to another.\n",
    "- **Text2Image Generation**: Creates an image based on a text description.\n",
    "\n",
    "### Generative Adversarial Networks (GANs)\n",
    "GANs are a type of generative model that uses two networks: a **generator** and a **discriminator**. The generator creates images, and the discriminator tries to distinguish between real and generated images. Over time, the generator improves its ability to create realistic images.\n",
    "\n",
    "### Image2Image Translation with Pix2Pix\n",
    "Pix2Pix is a type of GAN that performs image translation. For example, it can convert sketches into photorealistic images or grayscale images into color images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97ea15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define the generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(100, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(1024, 784),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return self.main(input).view(-1, 1, 28, 28)\n",
    "\n",
    "# Define the discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(784, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return self.main(input.view(-1, 784))\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "learning_rate = 0.0002\n",
    "epochs = 20\n",
    "\n",
    "# Prepare the MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "# Loss function and optimizers\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=learning_rate)\n",
    "optimizer_d = optim.Adam(discriminator.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training the GAN\n",
    "for epoch in range(epochs):\n",
    "    for i, (images, _) in enumerate(train_loader):\n",
    "        # Train the discriminator\n",
    "        real_images = images\n",
    "        real_labels = torch.ones(batch_size, 1)\n",
    "        fake_labels = torch.zeros(batch_size, 1)\n",
    "        \n",
    "        outputs = discriminator(real_images)\n",
    "        loss_real = criterion(outputs, real_labels)\n",
    "        \n",
    "        noise = torch.randn(batch_size, 100)\n",
    "        fake_images = generator(noise)\n",
    "        outputs = discriminator(fake_images.detach())\n",
    "        loss_fake = criterion(outputs, fake_labels)\n",
    "        \n",
    "        loss_d = loss_real + loss_fake\n",
    "        optimizer_d.zero_grad()\n",
    "        loss_d.backward()\n",
    "        optimizer_d.step()\n",
    "\n",
    "        # Train the generator\n",
    "        noise = torch.randn(batch_size, 100)\n",
    "        fake_images = generator(noise)\n",
    "        outputs = discriminator(fake_images)\n",
    "        loss_g = criterion(outputs, real_labels)\n",
    "        \n",
    "        optimizer_g.zero_grad()\n",
    "        loss_g.backward()\n",
    "        optimizer_g.step()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss D: {loss_d.item()}, Loss G: {loss_g.item()}\")\n",
    "\n",
    "print(\"Finished Training the GAN\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec0d3bd",
   "metadata": {},
   "source": [
    "\n",
    "## 6.2 Image2Image Translation with Pix2Pix\n",
    "Pix2Pix is a conditional GAN that is used for image translation tasks. For example, it can convert sketches into realistic images or grayscale images into color. Unlike traditional GANs, Pix2Pix uses paired data, where each input image has a corresponding target image.\n",
    "\n",
    "We will now use a pre-trained Pix2Pix model for an Image2Image task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94639eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Note: In practice, you'd download a pre-trained Pix2Pix model or train your own model on a dataset.\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Load a pre-trained Pix2Pix model (for example purposes)\n",
    "# model = torch.load('pix2pix_model.pth')\n",
    "\n",
    "# Load an image and apply the necessary transforms\n",
    "image = Image.open('input_image.jpg')\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "input_image = transform(image).unsqueeze(0)\n",
    "\n",
    "# Generate the translated image\n",
    "# output_image = model(input_image)\n",
    "\n",
    "# For demonstration, we'll just print the input shape\n",
    "print(f\"Input image shape: {input_image.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5c3fc6",
   "metadata": {},
   "source": [
    "\n",
    "## 6.3 Exercises:\n",
    "- Modify the GAN code to generate higher resolution images by increasing the size of the generator and discriminator networks.\n",
    "- Experiment with different image translation tasks using Pix2Pix, such as converting night images to day images.\n",
    "- Train a GAN on a custom dataset and evaluate the quality of the generated images.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
