{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4e4f117",
   "metadata": {},
   "source": [
    "\n",
    "# Week 4: Convolutional Neural Networks (CNN) for Image Classification\n",
    "## Objective:\n",
    "In this notebook, we will explore the architecture of Convolutional Neural Networks (CNNs) and how they are used for image classification tasks. We will implement a simple CNN using Python and PyTorch, and train it on a standard dataset such as MNIST.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61eb3186",
   "metadata": {},
   "source": [
    "\n",
    "## 4.1 Theory: What are Convolutional Neural Networks?\n",
    "Convolutional Neural Networks (CNNs) are a class of deep learning models designed to process and classify image data. CNNs use a combination of convolutional layers, pooling layers, and fully connected layers to extract features from images and perform classification.\n",
    "\n",
    "### Key Components of CNNs:\n",
    "- **Convolutional Layers**: These layers apply filters to the input image to detect features such as edges, textures, and patterns.\n",
    "- **Pooling Layers**: Pooling reduces the dimensionality of the feature maps while retaining the most important information.\n",
    "- **Fully Connected Layers**: After feature extraction, fully connected layers perform the final classification by using the extracted features.\n",
    "- **Activation Functions**: Commonly used activation functions include ReLU and Softmax for introducing non-linearity and making final predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff658b09-cecf-4ca7-84c9-28e34235cd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch==2.3.1 torchvision==0.18.1 torchaudio==2.3.1 --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f66c73c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Epoch 1, Batch 100, Loss: 0.954\n",
      "Epoch 1, Batch 200, Loss: 0.315\n",
      "Epoch 1, Batch 300, Loss: 0.183\n",
      "Epoch 1, Batch 400, Loss: 0.156\n",
      "Epoch 1, Batch 500, Loss: 0.144\n",
      "Epoch 1, Batch 600, Loss: 0.098\n",
      "Epoch 1, Batch 700, Loss: 0.101\n",
      "Epoch 1, Batch 800, Loss: 0.103\n",
      "Epoch 1, Batch 900, Loss: 0.089\n",
      "Epoch 1, Batch 1000, Loss: 0.094\n",
      "Epoch 1, Batch 1100, Loss: 0.083\n",
      "Epoch 1, Batch 1200, Loss: 0.081\n",
      "Epoch 1, Batch 1300, Loss: 0.077\n",
      "Epoch 1, Batch 1400, Loss: 0.082\n",
      "Epoch 1, Batch 1500, Loss: 0.065\n",
      "Epoch 1, Batch 1600, Loss: 0.066\n",
      "Epoch 1, Batch 1700, Loss: 0.079\n",
      "Epoch 1, Batch 1800, Loss: 0.057\n",
      "Epoch 2, Batch 100, Loss: 0.047\n",
      "Epoch 2, Batch 200, Loss: 0.042\n",
      "Epoch 2, Batch 300, Loss: 0.038\n",
      "Epoch 2, Batch 400, Loss: 0.053\n",
      "Epoch 2, Batch 500, Loss: 0.047\n",
      "Epoch 2, Batch 600, Loss: 0.040\n",
      "Epoch 2, Batch 700, Loss: 0.059\n",
      "Epoch 2, Batch 800, Loss: 0.040\n",
      "Epoch 2, Batch 900, Loss: 0.036\n",
      "Epoch 2, Batch 1000, Loss: 0.054\n",
      "Epoch 2, Batch 1100, Loss: 0.048\n",
      "Epoch 2, Batch 1200, Loss: 0.039\n",
      "Epoch 2, Batch 1300, Loss: 0.053\n",
      "Epoch 2, Batch 1400, Loss: 0.049\n",
      "Epoch 2, Batch 1500, Loss: 0.046\n",
      "Epoch 2, Batch 1600, Loss: 0.056\n",
      "Epoch 2, Batch 1700, Loss: 0.055\n",
      "Epoch 2, Batch 1800, Loss: 0.043\n",
      "Epoch 3, Batch 100, Loss: 0.032\n",
      "Epoch 3, Batch 200, Loss: 0.030\n",
      "Epoch 3, Batch 300, Loss: 0.031\n",
      "Epoch 3, Batch 400, Loss: 0.041\n",
      "Epoch 3, Batch 500, Loss: 0.030\n",
      "Epoch 3, Batch 600, Loss: 0.024\n",
      "Epoch 3, Batch 700, Loss: 0.036\n",
      "Epoch 3, Batch 800, Loss: 0.041\n",
      "Epoch 3, Batch 900, Loss: 0.031\n",
      "Epoch 3, Batch 1000, Loss: 0.033\n",
      "Epoch 3, Batch 1100, Loss: 0.032\n",
      "Epoch 3, Batch 1200, Loss: 0.032\n",
      "Epoch 3, Batch 1300, Loss: 0.043\n",
      "Epoch 3, Batch 1400, Loss: 0.036\n",
      "Epoch 3, Batch 1500, Loss: 0.046\n",
      "Epoch 3, Batch 1600, Loss: 0.025\n",
      "Epoch 3, Batch 1700, Loss: 0.027\n",
      "Epoch 3, Batch 1800, Loss: 0.041\n",
      "Epoch 4, Batch 100, Loss: 0.018\n",
      "Epoch 4, Batch 200, Loss: 0.016\n",
      "Epoch 4, Batch 300, Loss: 0.026\n",
      "Epoch 4, Batch 400, Loss: 0.013\n",
      "Epoch 4, Batch 500, Loss: 0.020\n",
      "Epoch 4, Batch 600, Loss: 0.014\n",
      "Epoch 4, Batch 700, Loss: 0.020\n",
      "Epoch 4, Batch 800, Loss: 0.024\n",
      "Epoch 4, Batch 900, Loss: 0.029\n",
      "Epoch 4, Batch 1000, Loss: 0.030\n",
      "Epoch 4, Batch 1100, Loss: 0.029\n",
      "Epoch 4, Batch 1200, Loss: 0.024\n",
      "Epoch 4, Batch 1300, Loss: 0.015\n",
      "Epoch 4, Batch 1400, Loss: 0.026\n",
      "Epoch 4, Batch 1500, Loss: 0.035\n",
      "Epoch 4, Batch 1600, Loss: 0.029\n",
      "Epoch 4, Batch 1700, Loss: 0.038\n",
      "Epoch 4, Batch 1800, Loss: 0.031\n",
      "Epoch 5, Batch 100, Loss: 0.020\n",
      "Epoch 5, Batch 200, Loss: 0.015\n",
      "Epoch 5, Batch 300, Loss: 0.009\n",
      "Epoch 5, Batch 400, Loss: 0.020\n",
      "Epoch 5, Batch 500, Loss: 0.019\n",
      "Epoch 5, Batch 600, Loss: 0.011\n",
      "Epoch 5, Batch 700, Loss: 0.021\n",
      "Epoch 5, Batch 800, Loss: 0.024\n",
      "Epoch 5, Batch 900, Loss: 0.029\n",
      "Epoch 5, Batch 1000, Loss: 0.018\n",
      "Epoch 5, Batch 1100, Loss: 0.019\n",
      "Epoch 5, Batch 1200, Loss: 0.015\n",
      "Epoch 5, Batch 1300, Loss: 0.019\n",
      "Epoch 5, Batch 1400, Loss: 0.017\n",
      "Epoch 5, Batch 1500, Loss: 0.024\n",
      "Epoch 5, Batch 1600, Loss: 0.021\n",
      "Epoch 5, Batch 1700, Loss: 0.013\n",
      "Epoch 5, Batch 1800, Loss: 0.014\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define the CNN architecture\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)  # 10 output classes for MNIST\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 32 * 7 * 7)  # Flatten the feature maps\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Load the MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Initialize the network, loss function, and optimizer\n",
    "cnn = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=0.001)\n",
    "\n",
    "# Train the CNN\n",
    "for epoch in range(5):  # 5 epochs\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = cnn(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:  # Print every 100 batches\n",
    "            print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c967456",
   "metadata": {},
   "source": [
    "\n",
    "## 4.2 Testing the CNN on the MNIST Test Set\n",
    "Now that we have trained our CNN, we will evaluate its performance on the MNIST test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ae05d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10,000 test images: 99.2%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# No gradient tracking for testing\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = cnn(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10,000 test images: {100 * correct / total}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304b1ae5",
   "metadata": {},
   "source": [
    "\n",
    "## 4.3 Exercises:\n",
    "- Modify the CNN architecture by adding more convolutional layers or increasing the number of filters. Observe the impact on accuracy and training time.\n",
    "- Experiment with different optimizers, such as SGD, and compare the results with Adam.\n",
    "- Train the CNN on a different dataset (e.g., CIFAR-10) and analyze the differences in performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f7d04d-aa64-4dbd-a944-21c02f50a7b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
