{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba3d2692-fcfa-4775-ac7a-d11d493d89cf",
   "metadata": {},
   "source": [
    "# Assignment: Named Entity and Event Extraction with LLMs\n",
    "\n",
    "This is a templete for assignment (NOT complete code)\n",
    "\n",
    "## Step 1: Load Libraries and Set Up Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b0fea9-9348-4b74-99ca-cbf9f8400aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Set up any configurations for LLM or API access\n",
    "# For example:\n",
    "# from openai import OpenAI\n",
    "# openai.api_key = \"your_api_key_here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "986b1ec9-f900-40d0-b197-89391c6e1b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 92 entries, 0 to 91\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   page    92 non-null     int64 \n",
      " 1   text    92 non-null     object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 1.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>88</td>\n",
       "      <td>กระเบื้องกาบู ขนาคกว้าง 16 เซนตีเมตร ยาว 31 เซ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>89</td>\n",
       "      <td>ฐานชุกชี   วัดสิงห์   ดินเผาด้านหลังทำเป็นแผงเ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>90</td>\n",
       "      <td># บทบรรณานกรม\\n\\nคณะกรรมการจัดทำหลักสูตรท้องถิ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>91</td>\n",
       "      <td>ศิลปากร. กรม. เครื่องด้วยจีนที่พบจากแหล่งโบราณ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>92</td>\n",
       "      <td>คำสังสำนักงานวัฒนธรรมจังหวัดปทุมธานี\\n\\n![6_7_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    page                                               text\n",
       "87    88  กระเบื้องกาบู ขนาคกว้าง 16 เซนตีเมตร ยาว 31 เซ...\n",
       "88    89  ฐานชุกชี   วัดสิงห์   ดินเผาด้านหลังทำเป็นแผงเ...\n",
       "89    90  # บทบรรณานกรม\\n\\nคณะกรรมการจัดทำหลักสูตรท้องถิ...\n",
       "90    91  ศิลปากร. กรม. เครื่องด้วยจีนที่พบจากแหล่งโบราณ...\n",
       "91    92  คำสังสำนักงานวัฒนธรรมจังหวัดปทุมธานี\\n\\n![6_7_..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_parquet('pages.parquet')\n",
    "df.info()\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a9b3d8b-6472-4df9-a19a-02bd99a3bfba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'กระเบื้องกาบู ขนาคกว้าง 16 เซนตีเมตร ยาว 31 เซนติเมตร สูง 20 เซนติเมตร สมัยอยุธยา ลายเทพนม\\n\\n![6_3_image_0.png](6_3_image_0.png)\\n\\n10.  ฐานชุกชี ฐานตั้งพระพุทธรูปมีหลากหลายรูปแบบ ส่วนใหญ่จากฐานหน้ากระดานต่อด้วย\\n\\n![6_3_image_1.png](6_3_image_1.png)\\n\\nฐานสิงห์หย่อนท้องสำเภา ต่อขึ้นด้วยชั้นบัวคว่ำบัวหงายหรือที่เรียกว่า บัวเชิงบาตร ตรงกลางปีดด้วย ผ้าทิพย์ซึ่งประดับด้วยลายต่าง ๆ เช่น ลายราชวัติ ลายแผงกุดั้นดอกจอก ปิดทองประดับกระจก ฐานชุกชี  วัดสิงห์  คินเผามีหลายหลายรูปแบบ  สมัยอยุธยา เตาอามโคก 84'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=df.loc[87,'text']\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24064a93-b4d2-41ae-a0f6-a63c64f88150",
   "metadata": {},
   "source": [
    "## Step 2: Load Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8fc803-5e0d-4051-93d8-db28ddaaf869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the text data for entity and event extraction\n",
    "# Example input:\n",
    "text = \"\"\"\n",
    "... (Paste your input text here) ...\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d926708-1b4e-4682-be17-22c13169c4ba",
   "metadata": {},
   "source": [
    "## Step 3: Entity Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac5cc7a-bfd0-4d78-9f53-a338eaf9511a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt for extracting named entities\n",
    "def extract_entities(text):\n",
    "    prompt = f\"\"\"\n",
    "    ### instruction\n",
    "    Extract all named entities (ATTRACTION, LOCATION, PERSON, ORGANIZATION, ANTIQUE, CULTURE) with detailed descriptions\n",
    "    from the following text. Format the output as a JSON array of entities.\n",
    "\n",
    "    # Example Output Format\n",
    "    [\n",
    "        {{\n",
    "            \"name\": \"วัดศาลาแดง\",\n",
    "            \"type\": \"ATTRACTION\",\n",
    "            \"description\": \"วัดที่มีชื่อเสียงในพื้นที่ อยู่ติดกับเมืองเมาะตะมะ เป็นจุดสำคัญของชุมชนในอดีตและปัจจุบัน.\"\n",
    "        }}\n",
    "    ]\n",
    "\n",
    "    ### input:\n",
    "    {text}\n",
    "\n",
    "    ### output:\n",
    "    \"\"\"\n",
    "    # Send the prompt to the LLM and retrieve response\n",
    "    # For example:\n",
    "    # response = openai.Completion.create(prompt=prompt)\n",
    "    # return json.loads(response['choices'][0]['text'].strip())\n",
    "    pass  # Replace with actual LLM call\n",
    "\n",
    "# Process the input text to extract entities\n",
    "entities = extract_entities(text)\n",
    "\n",
    "# Convert to DataFrame\n",
    "entity_df = pd.DataFrame(entities)\n",
    "entity_df['page'] = 1  # Replace with actual logic for page numbers\n",
    "entity_df['chunk'] = 0  # Replace with actual logic for chunks\n",
    "\n",
    "# Display entity DataFrame\n",
    "print(entity_df.head())\n",
    "entity_df.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c31b63b-0267-49ac-8656-3e1f4152290a",
   "metadata": {},
   "source": [
    "## Step 4: Event Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30f6c84-d2c8-48dd-b4b4-ed8386af6037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt for extracting events\n",
    "def extract_events(text):\n",
    "    prompt = f\"\"\"\n",
    "    ### instruction\n",
    "    Extract all events with their descriptions and time information from the following text.\n",
    "    Format the output as a JSON array of events.\n",
    "\n",
    "    # Example Output Format\n",
    "    [\n",
    "        {{\n",
    "            \"name\": \"วันอนุรักษ์มรดกไทย\",\n",
    "            \"description\": \"วันสำคัญที่ประชาชนร่วมมือกันเพื่ออนุรักษ์มรดกทางศิลปวัฒนธรรมของชาติไทย.\",\n",
    "            \"time\": \"2 เมษายน ทุกปี\"\n",
    "        }}\n",
    "    ]\n",
    "\n",
    "    ### input:\n",
    "    {text}\n",
    "\n",
    "    ### output:\n",
    "    \"\"\"\n",
    "    # Send the prompt to the LLM and retrieve response\n",
    "    # For example:\n",
    "    # response = openai.Completion.create(prompt=prompt)\n",
    "    # return json.loads(response['choices'][0]['text'].strip())\n",
    "    pass  # Replace with actual LLM call\n",
    "\n",
    "# Process the input text to extract events\n",
    "events = extract_events(text)\n",
    "\n",
    "# Convert to DataFrame\n",
    "event_df = pd.DataFrame(events)\n",
    "event_df['page'] = 1  # Replace with actual logic for page numbers\n",
    "event_df['chunk'] = 0  # Replace with actual logic for chunks\n",
    "\n",
    "# Display event DataFrame\n",
    "print(event_df.head())\n",
    "event_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d936420-b6fd-4250-87c9-39aa41899673",
   "metadata": {},
   "source": [
    "## Step 5: Validation and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449a53fa-eb86-4b8d-b9c9-4533c7d07798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "entity_df = pd.read_csv('entity.csv')\n",
    "entity_df = pd.read_csv('event.csv')\n",
    "\n",
    "# 1. Completeness\n",
    "# Calculate missing rate for entities and events\n",
    "entity_missing_rate = 1 - len(entity_df.dropna()) / len(entity_df)\n",
    "event_missing_rate = 1 - len(event_df.dropna()) / len(event_df)\n",
    "\n",
    "# Completeness score\n",
    "entity_completeness_score = (1 - entity_missing_rate) * 20\n",
    "event_completeness_score = (1 - event_missing_rate) * 20\n",
    "\n",
    "print(f\"Entity Completeness Score: {entity_completeness_score}\")\n",
    "print(f\"Event Completeness Score: {event_completeness_score}\")\n",
    "\n",
    "# 2. Accuracy\n",
    "# Evaluate the correctness of entity and event descriptions (manual step)\n",
    "# Example:\n",
    "incorrect_entity_points = 2  # Replace with manual evaluation results\n",
    "entity_accuracy_score = 20 - incorrect_entity_points * 5\n",
    "\n",
    "incorrect_event_points = 1  # Replace with manual evaluation results\n",
    "event_accuracy_score = 20 - incorrect_event_points * 5\n",
    "\n",
    "print(f\"Entity Accuracy Score: {entity_accuracy_score}\")\n",
    "print(f\"Event Accuracy Score: {event_accuracy_score}\")\n",
    "\n",
    "# 3. Consistency\n",
    "# Check for dirty or inconsistent data\n",
    "entity_dirty_rate = 0.1  # Replace with actual calculation\n",
    "event_dirty_rate = 0.05  # Replace with actual calculation\n",
    "\n",
    "entity_consistency_score = (1 - entity_dirty_rate) * 20\n",
    "event_consistency_score = (1 - event_dirty_rate) * 20\n",
    "\n",
    "print(f\"Entity Consistency Score: {entity_consistency_score}\")\n",
    "print(f\"Event Consistency Score: {event_consistency_score}\")\n",
    "\n",
    "# 4. Output Format\n",
    "# Ensure DataFrame format meets requirements\n",
    "entity_format_score = 20 if 'entity_df' in locals() else 0\n",
    "event_format_score = 20 if 'event_df' in locals() else 0\n",
    "\n",
    "print(f\"Entity Output Format Score: {entity_format_score}\")\n",
    "print(f\"Event Output Format Score: {event_format_score}\")\n",
    "\n",
    "# 5. Code Quality\n",
    "# Manual evaluation of code quality\n",
    "# Example:\n",
    "missing_headers = 1  # Replace with manual evaluation results\n",
    "code_quality_score = 20 - missing_headers * 5\n",
    "\n",
    "print(f\"Code Quality Score: {code_quality_score}\")\n",
    "\n",
    "## Final Scores\n",
    "total_entity_score = (\n",
    "    entity_completeness_score\n",
    "    + entity_accuracy_score\n",
    "    + entity_consistency_score\n",
    "    + entity_format_score\n",
    ")\n",
    "total_event_score = (\n",
    "    event_completeness_score\n",
    "    + event_accuracy_score\n",
    "    + event_consistency_score\n",
    "    + event_format_score\n",
    ")\n",
    "total_score = total_entity_score + total_event_score + code_quality_score\n",
    "\n",
    "print(f\"Total Entity Score: {total_entity_score}\")\n",
    "print(f\"Total Event Score: {total_event_score}\")\n",
    "print(f\"Total Assignment Score: {total_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d05197-f191-497f-926d-295f2373e7b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bb9687-79e4-40dd-89b1-c307876239e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
